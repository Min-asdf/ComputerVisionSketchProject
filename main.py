import os
import random
import numpy as np
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models, Input

# ====================================================
# [0] GPU ì„¤ì • (OOM ì˜¤ë¥˜ ë°©ì§€)
# ====================================================
# ìœˆë„ìš° TF 2.10 í™˜ê²½ì—ì„œ GPU ë©”ëª¨ë¦¬ ì¦ê°€ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤.
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        print(f"âœ… GPU ê°ì§€ë¨: {len(gpus)}ê°œ ì‚¬ìš© ê°€ëŠ¥")
        print(f"   ì¥ì¹˜ëª…: {gpus[0].name}")
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)
else:
    print("â„¹ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

# ====================================================
# [1] ì„¤ì •: ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ====================================================
# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
try:
    BASE_PATH = os.path.dirname(os.path.abspath(__file__))
except NameError:
    BASE_PATH = os.getcwd()

CLEAN_IMG_PATH = os.path.join(BASE_PATH, 'clean_images') # ì›ë³¸ ì´ë¯¸ì§€ í´ë”
DATASET_PATH = os.path.join(BASE_PATH, 'dataset')        # ìƒì„±ëœ ë°ì´í„°ì…‹ ì €ì¥ì†Œ
MODEL_SAVE_PATH = os.path.join(BASE_PATH, 'models')      # ëª¨ë¸ ì €ì¥ì†Œ

IMG_SIZE = 256  # ì´ë¯¸ì§€ í¬ê¸° (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 128ë¡œ ì¤„ì´ì„¸ìš”)
BATCH_SIZE = 4  # ë°°ì¹˜ í¬ê¸° (OOM ë°œìƒ ì‹œ 2ë¡œ ì¤„ì´ì„¸ìš”)
EPOCHS = 50     # í•™ìŠµ íšŸìˆ˜

# í´ë” ìë™ ìƒì„±
os.makedirs(DATASET_PATH, exist_ok=True)
os.makedirs(MODEL_SAVE_PATH, exist_ok=True)

# ====================================================
# [2] ë…¸ì´ì¦ˆ ìƒì„± í•¨ìˆ˜ë“¤ (OpenCV)
# ====================================================
def add_noise_line(img):
    img_copy = img.copy()
    h, w = img_copy.shape
    for _ in range(random.randint(5, 15)):
        x1, y1 = random.randint(0, w), random.randint(0, h)
        x2, y2 = random.randint(0, w), random.randint(0, h)
        cv2.line(img_copy, (x1, y1), (x2, y2), (0, 0, 0), random.randint(1, 3))
    return img_copy

def add_noise_cut(img):
    img_copy = img.copy()
    h, w = img_copy.shape
    for _ in range(random.randint(10, 30)):
        x, y = random.randint(0, w-20), random.randint(0, h-20)
        cv2.rectangle(img_copy, (x, y), (x+random.randint(5, 20), y+random.randint(5, 20)), (255, 255, 255), -1)
    return img_copy

def add_noise_thickness(img):
    kernel = np.ones((3,3), np.uint8)
    inverted_img = cv2.bitwise_not(img)
    dilated_img = cv2.dilate(inverted_img, kernel, iterations=1)
    return cv2.bitwise_not(dilated_img)

def add_noise_skew(img):
    rows, cols = img.shape
    pts1 = np.float32([[50, 50], [200, 50], [50, 200]])
    px, py = random.randint(-20, 20), random.randint(-20, 20)
    pts2 = np.float32([[50+px, 50+py], [200+px, 50-py], [50-px, 200+py]])
    M = cv2.getAffineTransform(pts1, pts2)
    return cv2.warpAffine(img, M, (cols, rows), borderValue=(255, 255, 255))

# ====================================================
# [3] ë°ì´í„°ì…‹ ìƒì„± ë° ë¡œë“œ ë¡œì§
# ====================================================
def generate_dataset():
    print("\nğŸš€ [1/4] ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
    if not os.path.exists(CLEAN_IMG_PATH):
        print(f"âŒ ì˜¤ë¥˜: '{CLEAN_IMG_PATH}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

    clean_files = [f for f in os.listdir(CLEAN_IMG_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not clean_files:
        print(f"âŒ ì˜¤ë¥˜: '{CLEAN_IMG_PATH}' í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¹˜ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        return False

    noise_functions = [add_noise_line, add_noise_cut, add_noise_thickness, add_noise_skew]
    count = 0
    
    for img_name in clean_files:
        img_path = os.path.join(CLEAN_IMG_PATH, img_name)
        clean_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if clean_img is None: continue
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        clean_img = cv2.resize(clean_img, (IMG_SIZE, IMG_SIZE))
        
        # ì €ì¥ í´ë” (sketch_01, sketch_02...)
        base_name = os.path.splitext(img_name)[0]
        save_dir = os.path.join(DATASET_PATH, base_name)
        os.makedirs(save_dir, exist_ok=True)

        # ì •ë‹µ ì €ì¥
        cv2.imwrite(os.path.join(save_dir, 'clean.png'), clean_img)

        # ë…¸ì´ì¦ˆ ì €ì¥
        for func in noise_functions:
            noisy_img = func(clean_img)
            fname = func.__name__.replace('add_', '') + '.png'
            cv2.imwrite(os.path.join(save_dir, fname), noisy_img)
        count += 1
        
    print(f"âœ… ì´ {count}ì„¸íŠ¸({count*4}ì¥) ë°ì´í„° ìƒì„± ì™„ë£Œ.")
    return True

def load_dataset_paths():
    X_paths = []
    Y_paths = []
    noise_types = ['noise_line.png', 'noise_cut.png', 'noise_thickness.png', 'noise_skew.png']

    for folder in os.listdir(DATASET_PATH):
        folder_full = os.path.join(DATASET_PATH, folder)
        if os.path.isdir(folder_full):
            clean_p = os.path.join(folder_full, 'clean.png')
            if os.path.exists(clean_p):
                for n_file in noise_types:
                    noisy_p = os.path.join(folder_full, n_file)
                    if os.path.exists(noisy_p):
                        X_paths.append(noisy_p)
                        Y_paths.append(clean_p)
    return X_paths, Y_paths

def load_image_tf(noisy_path, clean_path):
    # íŒŒì¼ ì½ê¸° ë° ë””ì½”ë”©
    noisy = tf.io.read_file(noisy_path)
    noisy = tf.image.decode_png(noisy, channels=1)
    clean = tf.io.read_file(clean_path)
    clean = tf.image.decode_png(clean, channels=1)
    
    # ì •ê·œí™” (0~1)
    noisy = tf.cast(noisy, tf.float32) / 255.0
    clean = tf.cast(clean, tf.float32) / 255.0
    
    # Diffusion Style ì…ë ¥ì„ ìœ„í•´ 3ì±„ë„ë¡œ ë³µì œ (í‘ë°± -> RGB í˜•íƒœ)
    noisy = tf.image.grayscale_to_rgb(noisy)
    return noisy, clean

# ====================================================
# [4] Diffusion Style U-Net ëª¨ë¸ (ResBlock + Attention)
# ====================================================
def ResBlock(x, filters):
    shortcut = x
    # ì±„ë„ ìˆ˜ê°€ ë‹¤ë¥´ë©´ 1x1 Convë¡œ ë§ì¶°ì¤ë‹ˆë‹¤.
    if x.shape[-1] != filters:
        shortcut = layers.Conv2D(filters, 1, padding='same')(x)
    
    # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)  # <--- GroupNormalization ëŒ€ì‹  ì´ê±° ì‚¬ìš©!
    x = layers.Activation("swish")(x)
    
    # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)  # <--- ì—¬ê¸°ë„ ë³€ê²½!

    # ì…ë ¥ê°’ê³¼ ê²°ê³¼ê°’ì„ ë”í•¨ (Residual Connection)
    return layers.Add()([x, shortcut])

def AttentionBlock(x):
    channels = x.shape[-1]
    q = layers.Conv2D(channels // 2, 1)(x)
    k = layers.Conv2D(channels // 2, 1)(x)
    v = layers.Conv2D(channels // 2, 1)(x)
    
    attn = layers.Multiply()([q, k])
    attn = layers.Activation("softmax")(attn)
    out = layers.Multiply()([attn, v])
    out = layers.Conv2D(channels, 1)(out)
    return layers.Add()([x, out])

def build_model():
    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))

    # Encoder
    x1 = layers.Conv2D(32, 3, padding='same')(inputs)
    x1 = ResBlock(x1, 32)
    p1 = layers.MaxPooling2D(2)(x1)

    x2 = ResBlock(p1, 64)
    x2 = AttentionBlock(x2)
    p2 = layers.MaxPooling2D(2)(x2)

    x3 = ResBlock(p2, 128)
    x3 = AttentionBlock(x3)
    p3 = layers.MaxPooling2D(2)(x3)

    # Bottleneck
    b = ResBlock(p3, 256)
    b = AttentionBlock(b)
    b = ResBlock(b, 256)

    # Decoder
    u1 = layers.UpSampling2D(2)(b)
    u1 = layers.Concatenate()([u1, x3])
    u1 = ResBlock(u1, 128)
    u1 = AttentionBlock(u1)

    u2 = layers.UpSampling2D(2)(u1)
    u2 = layers.Concatenate()([u2, x2])
    u2 = ResBlock(u2, 64)
    u2 = AttentionBlock(u2)

    u3 = layers.UpSampling2D(2)(u2)
    u3 = layers.Concatenate()([u3, x1])
    u3 = ResBlock(u3, 32)

    outputs = layers.Conv2D(1, 1, activation='sigmoid')(u3)
    return models.Model(inputs, outputs)

# ====================================================
# [5] ë©”ì¸ ì‹¤í–‰ ë£¨í‹´
# ====================================================
if __name__ == '__main__':
    # 1. ë°ì´í„° ìƒì„±
    if generate_dataset():
        X_paths, Y_paths = load_dataset_paths()
        
        if len(X_paths) > 0:
            # 2. ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
            print("\nğŸš€ [2/4] ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì¤‘...")
            dataset = tf.data.Dataset.from_tensor_slices((X_paths, Y_paths))
            dataset = dataset.map(load_image_tf)
            dataset = dataset.shuffle(400).batch(BATCH_SIZE)
            
            # 3. ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ
            print("\nğŸš€ [3/4] ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ ì‹œì‘...")
            model = build_model()
            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
            
            # (1) Best Model: ì„±ëŠ¥(loss)ì´ ê°€ì¥ ì¢‹ì„ ë•Œë§Œ ë®ì–´ì“°ê¸°
            best_save_path = os.path.join(MODEL_SAVE_PATH, 'sketch_unet_best.h5')
            checkpoint_best = tf.keras.callbacks.ModelCheckpoint(
                best_save_path, 
                save_best_only=True, 
                monitor='loss', 
                verbose=1
            )

            # (2) Final/Latest Model: ë§¤ Epochë§ˆë‹¤ ë¬´ì¡°ê±´ ì €ì¥ (ê°€ì¥ ìµœì‹  ìƒíƒœ ìœ ì§€)
            #     'save_best_only=False'ë¡œ ì„¤ì •í•˜ë©´ ë§¤ë²ˆ ë®ì–´ì”ë‹ˆë‹¤.
            final_save_path = os.path.join(MODEL_SAVE_PATH, 'sketch_unet_final.h5')
            checkpoint_final = tf.keras.callbacks.ModelCheckpoint(
                final_save_path, 
                save_best_only=False,  # <--- í•µì‹¬! ë¬´ì¡°ê±´ ì €ì¥
                verbose=0              # ë§¤ë²ˆ ì¶œë ¥í•˜ë©´ ì‹œë„ëŸ¬ìš°ë‹ˆ 0ìœ¼ë¡œ ì„¤ì •
            )

            # callbacks ë¦¬ìŠ¤íŠ¸ì— ë‘˜ ë‹¤ ì¶”ê°€
            history = model.fit(
                dataset, 
                epochs=EPOCHS, 
                callbacks=[checkpoint_best, checkpoint_final]
            )
            
            print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
            print(f"   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_save_path}")
            print(f"   - ìµœì¢… í•™ìŠµ ëª¨ë¸: {final_save_path}")

            # 4. ê²°ê³¼ í™•ì¸ (ì²« ë²ˆì§¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸)
            print("\nğŸš€ [4/4] í•™ìŠµ ê²°ê³¼ í…ŒìŠ¤íŠ¸...")
            
            # [ìˆ˜ì •] save_path ëŒ€ì‹  best_save_path ì‚¬ìš©
            if os.path.exists(best_save_path):
                best_model = tf.keras.models.load_model(best_save_path)
                print(f"ğŸ“‚ ìµœì  ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {best_save_path}")
            else:
                print("âš ï¸ ìµœì  ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í•™ìŠµëœ ë§ˆì§€ë§‰ ìƒíƒœ(model)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                best_model = model
            
            test_noisy_path = X_paths[0]
            test_img_raw = cv2.imread(test_noisy_path, cv2.IMREAD_GRAYSCALE)
            test_img = cv2.resize(test_img_raw, (IMG_SIZE, IMG_SIZE))
            
            # ì…ë ¥ ì „ì²˜ë¦¬
            input_tensor = test_img.astype(np.float32) / 255.0
            input_tensor = np.expand_dims(input_tensor, axis=-1)
            input_tensor = np.repeat(input_tensor, 3, axis=-1) # 3ì±„ë„ í™•ì¥
            input_tensor = np.expand_dims(input_tensor, axis=0) # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

            # ì˜ˆì¸¡
            pred = best_model.predict(input_tensor)
            result = (pred[0] * 255).astype(np.uint8)

            # ê²°ê³¼ ì‹œê°í™”
            plt.figure(figsize=(12, 6))
            plt.subplot(1, 2, 1)
            plt.title("Input (Noisy)")
            plt.imshow(test_img, cmap='gray')
            plt.axis('off')
            
            plt.subplot(1, 2, 2)
            plt.title("Output (AI Cleaned)")
            plt.imshow(result, cmap='gray')
            plt.axis('off')
            plt.show()
            
        else:
            print("âŒ ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")